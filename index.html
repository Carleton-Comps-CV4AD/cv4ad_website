<html>
<head>
    <title>CV4AD</title>
    <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="css/style.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@200&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>

    <div class = "titleGroup">
        <h1 class = "titles">CV4AD</h1>
        <h3 class = "subTitle">Computer Vision For Autonomous Driving</h3>
        <h3 class = "subTitle"><a class = "returnButton2" target="_blank" rel="noopener noreferrer" href ="https://www.linkedin.com/in/li-nathaniel/">Nathaniel Li</a> &nbsp &nbsp &nbsp <a class = "returnButton2" target="_blank" rel="noopener noreferrer" href="https://zehoubenzhao.com/">Ben Zhao</a> &nbsp &nbsp &nbsp <a class = "returnButton2" target="_blank" rel="noopener noreferrer">Ethan Massade</a> &nbsp &nbsp &nbsp <a class = "returnButton2" target="_blank" rel="noopener noreferrer">Josh Meier</a> &nbsp &nbsp &nbsp <a class = "returnButton2" target="_blank" rel="noopener noreferrer" href = "https://www.linkedin.com/in/julian-tanguma-373605215/">Julian Tanguma</a> &nbsp &nbsp &nbsp <a class = "returnButton2" target="_blank" rel="noopener noreferrer" href ="https://toledod.github.io/">David Toledo</a>
        </h3>
    </div>
        <div class="navbar">
            <nav>
                <a href="https://github.com/Carleton-Comps-CV4AD" target="_blank" rel="noopener noreferrer">Github</a>
                
                <a href="" target="_blank" rel="noopener noreferrer">Data</a>
                
                <a href="./presentation.html">Presentation</a>
            </nav>
        </div>
    <div class = "gifHolder">
        <img src="./images/gifs/video_49_clear_day.gif" alt="video of clear day simulation in CARLA">
    </div>
    <div class = "textHolder">
        <h3>Abstract</h3>
        <p class = "fillerText">filler text</p>
        <h3>Data</h3>
        <p class = "fillerText">For our project, our team used the CARLA simulator to generate an extensive dataset, which we split into training, validation, and test sets. The training and validation data were used to train our neural network and create weights for our models, which then processed the test data to produce segmentation masks and corresponding performance scores. Initially, CARLA provided a simple route featuring basic instances of vehicles and pedestrians. However, to meet the data-hungry demands of neural networks, we expanded our dataset to include diverse weather conditions—such as fog, rain, and nighttime—and collaborated with the instance segmentation and semantic segmentation teams to further augment our data with images, videos, and other data such as lidar data. This comprehensive effort resulted in the creation of over one million data files that significantly advanced our project.
        </p>
        <h3_1>Semantic Segmentation</h3_1>
        <figure class = "imageHolder">
            <img src="./images/imgs/0.png" alt="semantic segmentation output clear day">
            <figcaption>Clear Day</figcaption>
        </figure>
        <figure class = "imageHolder">
            <img src="./images/imgs/0foggy.png" alt="semantic segmentation output clear day">
            <figcaption>Foggy Day</figcaption>
        </figure>
        <figure class = "imageHolder">
            <img src="./images/imgs/0night.png" alt="semantic segmentation output clear day">
            <figcaption1>Clear Night</figcaption1>
            <figcaption1>Semantic Segmentation Ouput (RGB, Ground Truth, Prediction)</figcaption1>
        </figure>
        <p class = "fillerText">For our project, our team utilized semantic segmentation to analyze how different weather conditions 
            affect the ability of autonomous vehicles to detect objects and parse their environments. 
            Using a model adapted from MIT"S ADE20k dataset in PyTorch, our approach aimed ot benchmark performance across 4 distinct weatheer condtiions. 
            The model utilized an HRNETV2 archetecture with a single convolution module as the decoder to maintain high resolution representations of the data.
            The model was trained on a single NVIDIA GPU. Our approach was able to achieve a mean IOU of 0.65 on baseline data, a significant improvement over the original source code. 
        </p>
        <h3>Instance Segmentation</h3>
        <p class = "fillerText">filler text</p>
        <h3>Measured Effects of Weather</h3>
        <p class = "fillerText">filler text </p>
        <h3>Measured Mitigated Effects </h3>
        <p class = "fillerText">To address the problem of the weather, we decided to try three different solutions: Domain Adaptation, Deweathering, and Sensor Fusion. After generating new data sets for each solution, we applied them to our models to obtain new metrics to compare to our previous results. Domain adaptation had the best results out of the three, but all showed some signs of helping our weathering problem.</p>
    </div>
</body>

<div class = "gifHolder">
   <iframe width="1200" height="600" src="https://www.youtube.com/embed/NepRPRpq_i4?si=RgdeLRZud2XCf-3z" title="CV4AD Presentation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>

<div class = "textHolder">
    <p class = "fillerText2"> Special thank you to,
        <br>
         our advisor, <a class = "returnButton2" href = "https://www.cs.carleton.edu/faculty/tamert/" target="_blank" rel="noopener noreferrer">Tanya Amert</a> <br>
         and to <a class = "returnButton2" href = "https://people.carleton.edu/~mtie/index.html" target="_blank" rel="noopener noreferrer">Mike Tie</a>.
</p>

</div>

</html>
